{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b00025-7e20-4d83-bd62-642b42c50b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  8 11:38:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.77.01              Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P0             15W /   75W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cacb42ba-ce6a-4525-b8db-40a7e54bba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b636f9a-594d-4c1c-9174-62e98ef01872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryConv2D(layers.Layer):\n",
    "    def __init__(self, \n",
    "                 filters, \n",
    "                 kernel_size, \n",
    "                 strides=(1, 1), \n",
    "                 padding='valid', \n",
    "                 activation=None, \n",
    "                 **kwargs):\n",
    "        super(BinaryConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create trainable float32 weights\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=self.kernel_size + (input_shape[-1], self.filters),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # Create trainable bias (not binarized)\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias',\n",
    "            shape=(self.filters,),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        super(BinaryConv2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Binarize weights using sign function with Straight-Through Estimator (STE)\n",
    "        binary_kernel = tf.sign(self.kernel)\n",
    "        \n",
    "        # STE trick: Bypass gradient for binarization while keeping real-value weights\n",
    "        binary_kernel = binary_kernel + tf.stop_gradient(self.kernel - binary_kernel)\n",
    "        \n",
    "        # Perform convolution with binary weights\n",
    "        outputs = tf.nn.conv2d(\n",
    "            inputs,\n",
    "            binary_kernel,\n",
    "            strides=[1, self.strides[0], self.strides[1], 1],\n",
    "            padding=self.padding.upper()\n",
    "        )\n",
    "        \n",
    "        # Add bias\n",
    "        outputs = tf.nn.bias_add(outputs, self.bias)\n",
    "        \n",
    "        # Apply activation if specified\n",
    "        if self.activation is not None:\n",
    "            outputs = self.activation(outputs)\n",
    "            \n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'activation': tf.keras.activations.serialize(self.activation),\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd338e8-ff19-4646-9977-1703126aa64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Binary CNN Model\n",
    "def create_binary_model():\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.InputLayer(shape=(28, 28, 1)),\n",
    "        \n",
    "        # Block 1\n",
    "        BinaryConv2D(4, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "\n",
    "        BinaryConv2D(4, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "\n",
    "        layers.MaxPooling2D(2, name='pool1'),\n",
    "        \n",
    "        # Block 2\n",
    "        BinaryConv2D(8, (3, 3), activation='relu', padding='same', name='conv3'),\n",
    "\n",
    "        BinaryConv2D(8, (3, 3), activation='relu', padding='same', name='conv4'),\n",
    "\n",
    "        layers.MaxPooling2D(2, name='pool2'),\n",
    "        \n",
    "        # Block 3\n",
    "        BinaryConv2D(16, (3, 3), activation='relu', padding='same', name='conv5'),\n",
    "\n",
    "        layers.GlobalMaxPooling2D(name='pool3'),\n",
    "        \n",
    "        # Output\n",
    "        layers.Dense(10, activation='softmax', name='dense1')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd94c69-df00-4605-ad3d-c5f51df78010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "# Load and preprocess MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "plt.imshow(x_train[0], cmap=cm.Greys_r)\n",
    "plt.show()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "x_train = (x_train - 0.5) * 2.0  # Scale to [-1, 1]\n",
    "x_test = (x_test - 0.5) * 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb51b1aa-e27d-40cb-a6c7-94724cef1f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1741409012.685941   41580 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BinaryConv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BinaryConv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BinaryConv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BinaryConv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BinaryConv2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1 (\u001b[38;5;33mBinaryConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2 (\u001b[38;5;33mBinaryConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │           \u001b[38;5;34m148\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3 (\u001b[38;5;33mBinaryConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv4 (\u001b[38;5;33mBinaryConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv5 (\u001b[38;5;33mBinaryConv2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool3 (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m170\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,406</span> (9.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,406\u001b[0m (9.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,406</span> (9.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,406\u001b[0m (9.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Learning Rate Scheduling\n",
    "initial_learning_rate = 1e-3\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=600,  # Decay every 600 steps (≈2 epochs)\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "# cosine annealing\n",
    "# lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=20*len(x_train)//128\n",
    "# )\n",
    "\n",
    "# optimizer=tf.keras.optimizers.Adam(\n",
    "#     learning_rate=lr_schedule,\n",
    "#     clipvalue=0.5\n",
    "# )\n",
    "# Create and compile model\n",
    "model = create_binary_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# model.compile(optimizer=tf.keras.optimizers.SGD(\n",
    "#                     learning_rate=lr_schedule,\n",
    "#                     momentum=0.9,\n",
    "#                     nesterov=False,\n",
    "#                     weight_decay=1e-4,\n",
    "#                     clipnorm=None,\n",
    "#                     clipvalue=0.5,\n",
    "#                     global_clipnorm=None,\n",
    "#                     use_ema=False,\n",
    "#                     ema_momentum=0.99,\n",
    "#                     ema_overwrite_frequency=None,\n",
    "#                     loss_scale_factor=None,\n",
    "#                     gradient_accumulation_steps=None,\n",
    "#                     name=\"SGD\",\n",
    "#                 ),\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ac0961-a1f5-4bd9-bc69-1ffa0abe8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhat/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1418 - loss: 2.2974\n",
      "Epoch 1: val_loss improved from inf to 2.27227, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.1419 - loss: 2.2974 - val_accuracy: 0.2223 - val_loss: 2.2723\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/468\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.1875 - loss: 2.2785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhat/.local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 2.27227 to 2.27217, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 2.2785 - val_accuracy: 0.2212 - val_loss: 2.2722\n",
      "Epoch 3/10\n",
      "\u001b[1m467/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2116 - loss: 2.2676\n",
      "Epoch 3: val_loss improved from 2.27217 to 2.23269, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.2116 - loss: 2.2676 - val_accuracy: 0.2706 - val_loss: 2.2327\n",
      "Epoch 4/10\n",
      "\u001b[1m  1/468\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1875 - loss: 2.2541\n",
      "Epoch 4: val_loss improved from 2.23269 to 2.23265, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 2.2541 - val_accuracy: 0.2701 - val_loss: 2.2326\n",
      "Epoch 5/10\n",
      "\u001b[1m467/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2412 - loss: 2.2294\n",
      "Epoch 5: val_loss improved from 2.23265 to 2.19481, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.2412 - loss: 2.2294 - val_accuracy: 0.2750 - val_loss: 2.1948\n",
      "Epoch 6/10\n",
      "\u001b[1m  1/468\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.2422 - loss: 2.2219\n",
      "Epoch 6: val_loss improved from 2.19481 to 2.19461, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2422 - loss: 2.2219 - val_accuracy: 0.2744 - val_loss: 2.1946\n",
      "Epoch 7/10\n",
      "\u001b[1m467/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2525 - loss: 2.1877\n",
      "Epoch 7: val_loss improved from 2.19461 to 2.16524, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.2525 - loss: 2.1877 - val_accuracy: 0.2766 - val_loss: 2.1652\n",
      "Epoch 8/10\n",
      "\u001b[1m  1/468\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3281 - loss: 2.1468\n",
      "Epoch 8: val_loss did not improve from 2.16524\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3281 - loss: 2.1468 - val_accuracy: 0.2773 - val_loss: 2.1655\n",
      "Epoch 9/10\n",
      "\u001b[1m466/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2575 - loss: 2.1582\n",
      "Epoch 9: val_loss improved from 2.16524 to 2.13269, saving model to training_1/cp5.keras\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.2576 - loss: 2.1582 - val_accuracy: 0.2952 - val_loss: 2.1327\n",
      "Epoch 10/10\n",
      "\u001b[1m  1/468\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.2812 - loss: 2.1270\n",
      "Epoch 10: val_loss did not improve from 2.13269\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2812 - loss: 2.1270 - val_accuracy: 0.2945 - val_loss: 2.1328\n"
     ]
    }
   ],
   "source": [
    "# Create callbacks\n",
    "checkpoint_path = \"training_1/cp5.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# ModelCheckpoint to save the best model\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    monitor='val_loss',    # Monitor validation loss\n",
    "    mode='min',            # Minimization mode for val_loss\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping callback\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    # Monitor validation loss\n",
    "    patience=5,            # Stop after 5 epochs without improvement\n",
    "    restore_best_weights=True  # Restore weights from the best epoch\n",
    ")\n",
    "\n",
    "# Train with augmented data\n",
    "history = model.fit(\n",
    "    train_datagen.flow(x_train, y_train, batch_size=128),\n",
    "    steps_per_epoch=len(x_train) // 128,\n",
    "    epochs=10,             # Maximum number of epochs\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[cp_callback, early_stop]  # Both callbacks added\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493b1893-8d74-43ab-82f7-74492f1a62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 3ms/step - accuracy: 0.2952 - loss: 2.1327\n",
      "Restored model, accuracy: 29.52%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a629f1-a372-49f6-9669-359bb44c6f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique weight values after binarization: [[-1. -1.  1.]\n",
      " [ 1.  1. -1.]\n",
      " [ 1.  1.  1.]]\n",
      "Unique bias values after binarization: 0.563345\n"
     ]
    }
   ],
   "source": [
    "# for layer in model.layers: print(layer.get_config(), layer.get_weights())\n",
    "# Check weights in first convolutional layer\n",
    "conv1_weights = model.get_layer('conv1').get_weights()[0][:, :, 0, 0]\n",
    "print(\"Unique weight values after binarization:\", tf.sign(conv1_weights).numpy())\n",
    "conv1_bias = model.get_layer('conv1').get_weights()[1][0]\n",
    "print(\"Unique bias values after binarization:\", conv1_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29a25b64-dadf-4713-882c-74a0ca20db3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -0.7019608   0.99215686\n",
      "  -0.14509803 -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -0.31764704  0.9764706\n",
      "  -0.35686272 -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.          0.05882359  0.8901961\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -0.64705884  0.9137255   0.17647064\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -0.34117645  0.99215686 -0.5058824\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.          0.58431375  0.7490196  -0.9137255\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -0.7490196   0.99215686  0.69411767 -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -0.25490195  0.99215686  0.5294118  -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.          0.09803927  0.99215686 -0.3960784  -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.5529412   0.85882354  0.60784316 -0.9372549  -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.02745098  1.          0.2941177  -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.          0.3411765   0.99215686 -0.36470586 -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.8117647   0.81960785  0.6862745  -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.05882353  0.99215686  0.24705887 -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "   0.18431377  0.99215686  0.11372554 -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "   0.7882353   0.99215686 -0.4823529  -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -0.52156866\n",
      "   0.96862745  0.99215686 -0.4823529  -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.          0.10588241\n",
      "   0.99215686  0.60784316 -0.9764706  -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -0.92156863  0.6862745\n",
      "   0.99215686 -0.05098039 -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -0.9607843   0.5529412\n",
      "   0.3803922  -0.92156863 -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.        ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[0.05741075 0.25951067 0.05892769 0.05934335 0.12881453 0.06835531\n",
      " 0.08503688 0.0908468  0.07565336 0.11610067]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "mnist_og = x_test[2]\n",
    "plt.imshow(mnist_og, cmap=cm.Greys_r)\n",
    "plt.show()\n",
    "print(mnist_og.reshape(28,28))\n",
    "# mnist_og\n",
    "mnist_og.shape\n",
    "mnist_og = np.expand_dims(mnist_og, axis=0)\n",
    "prediction = model.predict(mnist_og)\n",
    "print(prediction[0])\n",
    "print(np.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71623b70-a516-4cdd-9372-8b9b6f073868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47  0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069\n",
      " 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069\n",
      " 0.069 0.069 0.069 0.    0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.203 0.295 0.707 0.536 0.256 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.127 0.    0.817 1.246 0.528\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.055\n",
      " 0.196 0.97  0.641 0.244 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.203 0.084 0.47  1.05  0.501 0.071 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.112 0.002 0.89  0.966 0.25  0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.073 0.304\n",
      " 1.027 0.649 0.136 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.202 0.    0.587 1.307 0.498 0.13  0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.14  0.038 0.718 1.205 0.517 0.182 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.21  0.875\n",
      " 0.877 0.414 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.205 0.101 0.445 1.081 0.622 0.101 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.09  0.106 0.84  1.217 0.419 0.1   0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.    0.275 0.988 0.895\n",
      " 0.353 0.187 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.201\n",
      " 0.    0.442 1.102 0.62  0.154 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.16  0.102 0.717 1.172 0.435 0.073 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.    0.238 1.045 1.002 0.355\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.\n",
      " 0.408 1.    0.82  0.358 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.205 0.    0.545 1.315 0.757 0.185 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.083 0.176 0.753 1.103 0.627 0.271\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.2   0.    0.389\n",
      " 1.001 1.008 0.394 0.104 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.178 0.    0.425 1.046 0.65  0.202 0.194 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.196 0.    0.142 0.557 0.251 0.037 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.203 0.342 0.282\n",
      " 0.    0.    0.183 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034 0.401 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199\n",
      " 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.199 0.034\n",
      " 0.653 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517\n",
      " 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517 0.517\n",
      " 0.517 0.517 0.517 0.339]\n"
     ]
    }
   ],
   "source": [
    "base_input = model.layers[0].input\n",
    "layer1_output1_np = np.round(tf.keras.Model(base_input, model.get_layer( model.layers[0].name ).output)(mnist_og)[0][:, :, 0].numpy().reshape(-1), 3)\n",
    "layer1_output2_np = np.round(tf.keras.Model(base_input, model.get_layer( model.layers[0].name ).output)(mnist_og)[0][:, :, 1].numpy().reshape(-1), 2)\n",
    "plt.imshow(layer1_output1_np.reshape((28,28)), cmap=cm.Greys_r)\n",
    "plt.show()\n",
    "plt.imshow(layer1_output2_np.reshape((28,28)), cmap=cm.Greys_r)\n",
    "plt.show()\n",
    "print(layer1_output1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e23ea67b-ba04-4bc9-901c-ae36150b6bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1\n",
      "[[[[-0.19885893 -0.34258297  0.06034872  0.30173618]]\n",
      "\n",
      "  [[-0.02392298 -0.32710353 -0.16229163 -0.01445088]]\n",
      "\n",
      "  [[ 0.09287417 -0.06873024  0.01022124  0.06027612]]]\n",
      "\n",
      "\n",
      " [[[ 0.3346632   0.3122937   0.2804963   0.15272933]]\n",
      "\n",
      "  [[ 0.112059   -0.00667903 -0.17016308  0.2462635 ]]\n",
      "\n",
      "  [[-0.27068147  0.34677833  0.3321393  -0.29107302]]]\n",
      "\n",
      "\n",
      " [[[ 0.0662308  -0.27769452 -0.1815401   0.1627512 ]]\n",
      "\n",
      "  [[ 0.23948252  0.29109663 -0.2843106   0.07333562]]\n",
      "\n",
      "  [[ 0.01246604 -0.21477778  0.00137901 -0.35236326]]]]\n",
      "[0.563345   0.18315034 0.20255055 0.5650977 ]\n",
      "Layer: conv2\n",
      "[[[[-1.63321778e-01  1.92152977e-01  7.92703331e-02 -2.02344060e-01]\n",
      "   [ 1.19772971e-01 -2.41256148e-01  1.08440250e-01 -1.67931154e-01]\n",
      "   [ 1.90798581e-01  1.81072950e-03 -1.32924020e-01 -7.06217289e-02]\n",
      "   [-1.91474095e-01 -7.84950852e-02  2.80600607e-01 -1.33285493e-01]]\n",
      "\n",
      "  [[-2.11679399e-01 -6.47490472e-02  1.63359493e-01 -2.28124857e-02]\n",
      "   [-8.18653405e-02  2.10172623e-01  2.35568523e-01 -1.26803502e-01]\n",
      "   [-5.65758795e-02 -2.74690688e-01  3.16064060e-02  3.30433249e-02]\n",
      "   [ 6.47844374e-02  1.62013888e-01 -2.88579047e-01  4.30990756e-02]]\n",
      "\n",
      "  [[-2.82881320e-01  8.64411891e-02  2.14525461e-01 -8.76902491e-02]\n",
      "   [-6.52289689e-02  7.28138983e-02  5.16982079e-02  2.23809302e-01]\n",
      "   [-1.33025348e-02 -1.39179304e-01 -8.43798071e-02  2.27757752e-01]\n",
      "   [ 1.64232135e-01  1.66453481e-01 -1.48897663e-01  1.00501984e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.07917595e-04 -8.94518942e-02 -2.05384076e-01 -8.27521533e-02]\n",
      "   [-4.83989716e-05 -1.14376172e-01  1.02595568e-01  5.08108437e-02]\n",
      "   [ 5.47772646e-02 -3.29276323e-02 -1.04951546e-01  1.13560110e-01]\n",
      "   [ 1.05627626e-01 -9.09443796e-02 -1.38286695e-01  2.41040289e-01]]\n",
      "\n",
      "  [[-2.45671153e-01  2.66499341e-01  1.79270446e-01 -1.89909697e-01]\n",
      "   [-5.86219281e-02 -5.97871393e-02  2.45624900e-01  2.15305567e-01]\n",
      "   [ 1.69941187e-02 -6.15727454e-02 -2.11125776e-01 -1.55732930e-02]\n",
      "   [ 3.21428776e-02 -1.63029611e-01  1.48621470e-01  1.80675298e-01]]\n",
      "\n",
      "  [[-2.19425023e-01 -1.93119228e-01 -5.25215715e-02 -2.24134073e-01]\n",
      "   [-1.21673122e-01  9.19717550e-02  2.33139694e-02  2.42405295e-01]\n",
      "   [-2.02636689e-01  1.30334944e-01  3.47795188e-02  2.53718257e-01]\n",
      "   [-1.46740124e-01 -1.09952480e-01  7.88336992e-02  2.59184837e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.62427738e-01  3.91365290e-02 -1.69008672e-02 -1.81650966e-01]\n",
      "   [ 6.75562322e-02  2.37991452e-01  1.45435333e-04  2.02110738e-01]\n",
      "   [-6.69871122e-02 -4.00641561e-02 -1.34403765e-01 -2.19075888e-01]\n",
      "   [-2.92867422e-03 -1.36958167e-01  3.48740220e-02  2.29956388e-01]]\n",
      "\n",
      "  [[ 2.34256685e-02 -2.78517097e-01  7.64352679e-02 -5.80954105e-02]\n",
      "   [-1.11598775e-01 -1.88842624e-01 -4.46489751e-02  4.97965813e-02]\n",
      "   [-2.63828635e-01 -2.53836691e-01 -2.84195274e-01  1.00420147e-01]\n",
      "   [ 3.92951667e-02 -1.61581382e-01  2.18305290e-01  1.43371791e-01]]\n",
      "\n",
      "  [[-1.29080325e-01  1.86766773e-01  2.60394394e-01  9.66994464e-02]\n",
      "   [-2.60899961e-01  1.49569809e-01  5.97552657e-02 -2.25074857e-01]\n",
      "   [ 1.65059745e-01 -8.99431705e-02  5.64707220e-02 -1.60115615e-01]\n",
      "   [ 3.13542783e-02 -1.44373700e-01 -1.69241190e-01 -1.08424410e-01]]]]\n",
      "[0.94146276 0.31663993 0.06153119 0.17179105]\n",
      "Layer: pool1\n",
      "Layer: conv3\n",
      "[[[[-0.14486253  0.18060656 -0.1502566  -0.16962966  0.02347456\n",
      "     0.1475537   0.02537252 -0.20314686]\n",
      "   [-0.17929961  0.10779293  0.18156211 -0.08921218  0.0900916\n",
      "     0.14832224  0.14476712 -0.13383603]\n",
      "   [ 0.04698481  0.01447861 -0.09097724 -0.19027892  0.21325703\n",
      "     0.05724822  0.18065028  0.05539416]\n",
      "   [-0.10771881  0.14181949 -0.03019463  0.22498189 -0.19610429\n",
      "     0.00377703  0.01488735  0.06519826]]\n",
      "\n",
      "  [[-0.22178549  0.01947798 -0.13231099 -0.06629081 -0.18304034\n",
      "    -0.1442771   0.04769112 -0.09089805]\n",
      "   [ 0.10829683  0.1526493  -0.03939641  0.1203251   0.18840642\n",
      "    -0.03393546 -0.14300427 -0.00212897]\n",
      "   [-0.14802985 -0.00044304 -0.07492614  0.09590791 -0.20475215\n",
      "     0.02135329 -0.21580389  0.10137521]\n",
      "   [-0.12916401  0.09980436  0.03548034  0.11948599  0.06337093\n",
      "    -0.04892614 -0.14736578 -0.1676623 ]]\n",
      "\n",
      "  [[-0.06110062  0.01751994 -0.02158716  0.07392816  0.19581003\n",
      "     0.18548097 -0.07184555 -0.00824651]\n",
      "   [-0.00486015  0.10164471 -0.17156449 -0.02443905 -0.23507208\n",
      "    -0.21288013 -0.07453732  0.22370727]\n",
      "   [-0.03007077 -0.18057525  0.13484626 -0.16539581 -0.03074966\n",
      "     0.00241052 -0.07101671 -0.2166207 ]\n",
      "   [ 0.16165622  0.0241928   0.22773589 -0.11348781  0.13847403\n",
      "     0.22170843 -0.21863987 -0.06724575]]]\n",
      "\n",
      "\n",
      " [[[-0.15123576 -0.08280709 -0.18526512 -0.22823389 -0.15621865\n",
      "    -0.09357674  0.0834951  -0.03890474]\n",
      "   [-0.153792   -0.11527618 -0.02556038  0.17399977 -0.22102684\n",
      "     0.02158655 -0.20454484 -0.18526664]\n",
      "   [ 0.21984713 -0.0457554  -0.11138468 -0.22730638 -0.17927544\n",
      "     0.16536446  0.22405787  0.21891044]\n",
      "   [ 0.08232324 -0.01761962  0.1714875  -0.07774177 -0.1919757\n",
      "    -0.09525952 -0.17663929 -0.03251669]]\n",
      "\n",
      "  [[ 0.0898305   0.22869752 -0.1772044   0.12368588  0.06001027\n",
      "     0.01217145  0.03479369 -0.04648983]\n",
      "   [ 0.19015248  0.13181816 -0.19702551 -0.09940542 -0.12499648\n",
      "    -0.07231084 -0.08427504  0.02291654]\n",
      "   [ 0.08039181 -0.04388206 -0.2256585  -0.19521229 -0.13045415\n",
      "     0.08185621  0.16314219 -0.2152824 ]\n",
      "   [ 0.08467482 -0.23542792 -0.02419886  0.0912997   0.13807027\n",
      "     0.21112548  0.04775284 -0.06527986]]\n",
      "\n",
      "  [[ 0.17952     0.05775996 -0.13445008  0.18686698  0.19256456\n",
      "     0.11503358 -0.12161709 -0.07584219]\n",
      "   [ 0.19030909 -0.14998585 -0.15735379  0.19709541  0.1927649\n",
      "     0.0625322  -0.01595382  0.02906464]\n",
      "   [-0.04645494 -0.07355227 -0.1337505   0.06721495 -0.12701312\n",
      "    -0.00415315  0.10940923 -0.21839687]\n",
      "   [ 0.17557378 -0.01280123  0.15564169  0.14349546 -0.1878235\n",
      "    -0.04817615  0.05464204 -0.01291446]]]\n",
      "\n",
      "\n",
      " [[[-0.22391069 -0.22004066  0.13165568  0.13692145 -0.11783455\n",
      "     0.18171169  0.03992684 -0.04942854]\n",
      "   [-0.05024265  0.12655546 -0.02443843  0.1258951  -0.06565793\n",
      "     0.21968006  0.22170506 -0.15789676]\n",
      "   [ 0.01928516  0.1299669   0.00420873  0.08418794 -0.07640825\n",
      "     0.11994179  0.10676847 -0.03252393]\n",
      "   [-0.15055832 -0.01333728 -0.19676712  0.09588538  0.1285417\n",
      "     0.13241653 -0.10789363  0.16006126]]\n",
      "\n",
      "  [[-0.01662822 -0.09564547 -0.12358575 -0.11669097  0.22621517\n",
      "     0.14423    -0.04809916 -0.21848752]\n",
      "   [ 0.06703176  0.1767206  -0.11887518 -0.10644035  0.12523814\n",
      "     0.12541823 -0.11855897 -0.11710238]\n",
      "   [-0.13183838 -0.10551149  0.03569169  0.15804227  0.14540298\n",
      "    -0.13248941 -0.15301806 -0.03061901]\n",
      "   [ 0.05875798  0.14835186  0.21590994  0.04855727 -0.2055857\n",
      "     0.08700509 -0.07406606 -0.22002189]]\n",
      "\n",
      "  [[-0.08416833  0.17243193 -0.02833004 -0.08579075 -0.03425252\n",
      "    -0.12444964 -0.03307831 -0.22567692]\n",
      "   [-0.20923212  0.15812014 -0.13850439  0.2007504  -0.14205864\n",
      "    -0.05204433 -0.13668004  0.22440459]\n",
      "   [-0.2000871   0.1583529   0.0284353   0.13317673 -0.19434014\n",
      "    -0.17530032 -0.16762841 -0.0245737 ]\n",
      "   [-0.12797457 -0.12586685  0.00161518  0.02858146 -0.22961867\n",
      "     0.10982053  0.00218961  0.16440664]]]]\n",
      "[ 0.03217817  0.30535206 -0.35805404  0.3418916  -0.20047663  0.0066202\n",
      "  0.05770962 -0.12147725]\n",
      "Layer: conv4\n",
      "[[[[-0.15170026 -0.08978675  0.01552194 -0.11974095 -0.1036256\n",
      "     0.13378116 -0.15705514  0.07727769]\n",
      "   [-0.0111118   0.0488784   0.08548597 -0.18942079 -0.10291229\n",
      "    -0.1891993   0.09647894  0.01734725]\n",
      "   [ 0.1006791   0.05663574  0.02480367 -0.13366102  0.08906016\n",
      "    -0.19237268  0.03348279  0.04685351]\n",
      "   [-0.03486075 -0.1622484  -0.16409594  0.06065896 -0.00798313\n",
      "     0.15747797 -0.12820184  0.14248118]\n",
      "   [ 0.02385081  0.13610974  0.16569725  0.14106768 -0.19296598\n",
      "    -0.12844571 -0.12348548  0.17675063]\n",
      "   [-0.08755022 -0.02407984 -0.02148493  0.00826974 -0.13891637\n",
      "     0.09324804 -0.12576334  0.13284415]\n",
      "   [ 0.0846951   0.04537661 -0.09778999 -0.06111333  0.04383917\n",
      "    -0.03780808 -0.08348375 -0.13712814]\n",
      "   [ 0.10338762 -0.14193688 -0.11343088 -0.19151853  0.02712902\n",
      "    -0.02194068 -0.09047023 -0.11959343]]\n",
      "\n",
      "  [[-0.00206761  0.13486713 -0.09454045  0.07756647 -0.1762936\n",
      "    -0.00283718  0.04781339 -0.12602493]\n",
      "   [ 0.18352267 -0.05002791 -0.18729798  0.17887557 -0.19103579\n",
      "    -0.10305922 -0.04323167  0.04022142]\n",
      "   [ 0.18926501 -0.19657366  0.16818744  0.11631441 -0.05238636\n",
      "    -0.07959564 -0.12762456 -0.1708699 ]\n",
      "   [-0.1588566  -0.03652745  0.07462546  0.04929164 -0.11603398\n",
      "    -0.1464453  -0.1443786   0.08157381]\n",
      "   [ 0.18963063 -0.1532746   0.18634221 -0.05236164 -0.17622584\n",
      "    -0.20011574  0.18894637 -0.1352241 ]\n",
      "   [ 0.19205582 -0.16194846 -0.18646349  0.09275803  0.04991734\n",
      "     0.09267849  0.19056058 -0.15002349]\n",
      "   [ 0.02765974  0.126822   -0.16326919 -0.08594327 -0.02931319\n",
      "    -0.1718922  -0.14428657 -0.02102697]\n",
      "   [ 0.04903919  0.0348208  -0.16062024 -0.16468218  0.1334019\n",
      "    -0.16961654 -0.09248597 -0.07782674]]\n",
      "\n",
      "  [[ 0.00774822  0.03499264 -0.17454572 -0.11390947 -0.03773381\n",
      "     0.18741584 -0.12375116  0.15783703]\n",
      "   [ 0.05369264  0.189001    0.0160657  -0.12706849 -0.0524217\n",
      "    -0.18958202 -0.16691965  0.15466413]\n",
      "   [-0.00808918  0.09506756 -0.09861708  0.13330686  0.02094325\n",
      "    -0.04292575  0.1163148   0.08877802]\n",
      "   [ 0.1690116  -0.05695187 -0.11634073 -0.0380186   0.06850055\n",
      "     0.02253029  0.07020384  0.10765046]\n",
      "   [-0.09074004  0.05586532 -0.0649516  -0.01667024  0.11455753\n",
      "    -0.03093985  0.07489714 -0.08843245]\n",
      "   [ 0.1943137   0.08578098 -0.01184681  0.0288644   0.19625601\n",
      "    -0.03259943  0.05273113 -0.10727163]\n",
      "   [-0.04239289 -0.0037806   0.20087963 -0.1499317   0.05631801\n",
      "     0.02913882  0.02788648  0.07375863]\n",
      "   [-0.11294942  0.02388211 -0.07363325  0.18182266  0.08561024\n",
      "    -0.07760234  0.05527481  0.18948269]]]\n",
      "\n",
      "\n",
      " [[[ 0.01409274  0.0086126  -0.03617246  0.1790717   0.02232681\n",
      "    -0.15748356 -0.18660623 -0.09817611]\n",
      "   [ 0.15149459  0.00140609  0.08789238 -0.19275525 -0.00764817\n",
      "    -0.08715727 -0.16491413  0.04980808]\n",
      "   [ 0.09237093 -0.11210767  0.14514759 -0.04420651 -0.05260152\n",
      "    -0.07854244 -0.10382032  0.06517431]\n",
      "   [ 0.14963037  0.19301537  0.18090823  0.1204876   0.07578462\n",
      "     0.05618474  0.12249938 -0.02862354]\n",
      "   [ 0.15925708  0.04855171 -0.00140433  0.05261379  0.05880788\n",
      "     0.06130937  0.11441779 -0.13921684]\n",
      "   [-0.17892988  0.08885995 -0.1270738   0.17630017 -0.06222649\n",
      "     0.04659459 -0.06052612  0.04915205]\n",
      "   [-0.0025354   0.10707167  0.01212299  0.19346282  0.01350115\n",
      "    -0.08858696  0.10091689 -0.01323187]\n",
      "   [-0.08959817  0.03430974 -0.04341646 -0.09201716 -0.09922285\n",
      "    -0.2014461   0.18715557  0.02688146]]\n",
      "\n",
      "  [[ 0.11849126  0.10607463 -0.15414496  0.02103329  0.09781665\n",
      "    -0.03186695  0.02206887  0.1734634 ]\n",
      "   [ 0.11426738 -0.13355619  0.14384809  0.13476324 -0.14220178\n",
      "     0.08468854 -0.12521365 -0.14477476]\n",
      "   [ 0.0744361  -0.04301189 -0.01918872  0.01087493 -0.03737499\n",
      "    -0.09199322 -0.01834404 -0.07748355]\n",
      "   [-0.18098441  0.00232871 -0.19783258  0.01737164  0.16457915\n",
      "    -0.05310751  0.0977715  -0.13476795]\n",
      "   [-0.1319421  -0.19866663 -0.18436103  0.15251037  0.1083295\n",
      "     0.13275105  0.12707609 -0.09946778]\n",
      "   [ 0.0168106   0.01055889 -0.00777665 -0.10643203  0.18636256\n",
      "     0.19603565  0.13663983  0.03863302]\n",
      "   [-0.1135103  -0.10620568 -0.09339619 -0.03049469 -0.07899076\n",
      "     0.06712171 -0.00979978  0.02432683]\n",
      "   [ 0.06539607  0.14048642  0.10068211 -0.18631831 -0.13161048\n",
      "    -0.03238247 -0.11049811  0.16682091]]\n",
      "\n",
      "  [[ 0.05020711 -0.18689944 -0.16116643  0.14995116  0.01970623\n",
      "     0.0112354   0.11662042  0.12419996]\n",
      "   [ 0.1429972   0.05687132 -0.06183097  0.1370931  -0.13692808\n",
      "     0.06683579 -0.15507795  0.16044456]\n",
      "   [ 0.11433274  0.15343073 -0.19850643  0.20098999 -0.03030986\n",
      "     0.12975621  0.01199801  0.12555563]\n",
      "   [-0.00923918  0.15486464  0.04457764  0.12379268 -0.08225787\n",
      "    -0.10262208 -0.00325261  0.03063197]\n",
      "   [ 0.10677531  0.14032042 -0.06372675 -0.14256197 -0.17228533\n",
      "     0.09606203 -0.19487095 -0.09910848]\n",
      "   [ 0.03742385 -0.09005043  0.1507228   0.13875932 -0.16761783\n",
      "    -0.19947587  0.1075362   0.0861581 ]\n",
      "   [-0.19837381  0.10536572 -0.05855198  0.15797228  0.17056224\n",
      "    -0.0753821   0.01791909  0.15981448]\n",
      "   [-0.02720529 -0.0338439   0.17036721  0.06063026  0.17585555\n",
      "     0.03667954  0.0677298   0.09903294]]]\n",
      "\n",
      "\n",
      " [[[-0.17904994 -0.05821696 -0.15661962  0.04585914  0.20185092\n",
      "     0.11269113  0.11689708 -0.01732486]\n",
      "   [-0.01826686 -0.06556267 -0.00464872  0.05734     0.0873991\n",
      "    -0.03734797  0.000975   -0.09779102]\n",
      "   [ 0.11563677  0.17916635  0.04420725  0.00856467  0.19508767\n",
      "    -0.05331814 -0.10385112  0.00034593]\n",
      "   [-0.19594648  0.02989876 -0.15089862  0.12406954 -0.03511937\n",
      "    -0.09919953  0.09046263 -0.20186834]\n",
      "   [ 0.13933024 -0.13894236  0.18158725 -0.19994867  0.1023041\n",
      "     0.01466896 -0.0396378  -0.19936578]\n",
      "   [-0.11835773 -0.08814225  0.03775157 -0.13909279  0.1329408\n",
      "    -0.02179323 -0.10383506  0.16230217]\n",
      "   [-0.20136255  0.07914308  0.14993614 -0.08658709 -0.14443195\n",
      "    -0.03251947 -0.1950607  -0.07340807]\n",
      "   [-0.10178351 -0.15207514  0.04232486  0.08048138 -0.05331396\n",
      "    -0.07812458  0.09937444  0.1313045 ]]\n",
      "\n",
      "  [[ 0.03236496 -0.18472365 -0.1337634   0.15981647 -0.14776914\n",
      "    -0.19205514  0.1380187  -0.02301282]\n",
      "   [ 0.13083664 -0.02515377  0.01955372  0.00059462 -0.08885444\n",
      "     0.15676787  0.0233749   0.18834063]\n",
      "   [-0.18616745  0.0583089   0.0322811   0.1358448  -0.17703858\n",
      "    -0.11981434  0.0583396   0.11299196]\n",
      "   [-0.10028271  0.02911648  0.04749271  0.14078721 -0.12849975\n",
      "    -0.20108597  0.10754538 -0.19495821]\n",
      "   [ 0.06333402  0.11381131 -0.06135608 -0.03171968 -0.13469641\n",
      "     0.19947869  0.06001934  0.20229715]\n",
      "   [ 0.15551063 -0.05868144  0.1425949  -0.08714633 -0.1899442\n",
      "     0.04138476  0.05595118 -0.13438134]\n",
      "   [-0.19230303 -0.06003998  0.17380762 -0.04382905 -0.08292773\n",
      "     0.01745564  0.18662852  0.07697448]\n",
      "   [ 0.05030391  0.16529465 -0.05249684 -0.10236177 -0.01992403\n",
      "     0.00704819  0.05890876 -0.05146112]]\n",
      "\n",
      "  [[-0.18820128  0.19955748  0.05313429  0.00314778 -0.14999507\n",
      "     0.1059863   0.12308875 -0.08023512]\n",
      "   [-0.12485122 -0.03700833  0.12413561  0.19254497  0.11973006\n",
      "     0.16324446  0.07255828 -0.06481567]\n",
      "   [-0.10206125 -0.07076994  0.12027818 -0.17034502 -0.04323635\n",
      "     0.04654208 -0.1133735   0.03716372]\n",
      "   [ 0.17275435 -0.06265496 -0.05716206  0.18059683  0.20165193\n",
      "    -0.13676056  0.08955973  0.00224958]\n",
      "   [-0.1314953   0.1178242  -0.08398414  0.15956733  0.1660969\n",
      "    -0.00727318 -0.07848789 -0.02918102]\n",
      "   [ 0.11925963  0.14884609 -0.05774216 -0.14533618 -0.06044713\n",
      "    -0.11991367  0.00907148  0.16547725]\n",
      "   [ 0.1950993  -0.0046735  -0.16298915  0.00958769 -0.10464644\n",
      "     0.00031     0.10821202  0.03702186]\n",
      "   [ 0.06404012 -0.16445701 -0.15458953  0.07588264 -0.00171867\n",
      "     0.01668641  0.13271868 -0.04305407]]]]\n",
      "[-0.1962516   0.01416508  0.03457903 -0.16025218  0.23739083  0.06889526\n",
      "  0.06753221 -0.0408507 ]\n",
      "Layer: pool2\n",
      "Layer: conv5\n",
      "[[[[-0.02524209 -0.13781726 -0.05953729 ...  0.01074524  0.1598676\n",
      "     0.0841765 ]\n",
      "   [-0.02762675 -0.00695221  0.13696219 ... -0.0445288  -0.1399372\n",
      "     0.06354932]\n",
      "   [-0.10947709  0.00712033  0.00697275 ...  0.04069369 -0.03502195\n",
      "    -0.13836782]\n",
      "   ...\n",
      "   [-0.09825528  0.07948522 -0.10191198 ... -0.09955895 -0.09755743\n",
      "     0.04089856]\n",
      "   [ 0.1516728  -0.08365997  0.05871303 ...  0.12355413 -0.14364867\n",
      "    -0.09002769]\n",
      "   [-0.06772359  0.02469552 -0.05136161 ...  0.08401228  0.07307279\n",
      "     0.1521899 ]]\n",
      "\n",
      "  [[-0.09083001  0.14983393 -0.0071853  ...  0.11820979  0.15341617\n",
      "     0.02857184]\n",
      "   [-0.03488171  0.08016439  0.02641368 ...  0.08737715 -0.11086969\n",
      "     0.09004064]\n",
      "   [ 0.00075662 -0.02026141 -0.02890337 ... -0.08652385 -0.09649162\n",
      "    -0.01634495]\n",
      "   ...\n",
      "   [-0.0533032   0.09220178 -0.13680713 ...  0.00928764  0.12036581\n",
      "     0.07673533]\n",
      "   [-0.13621628 -0.12399332 -0.15010504 ...  0.09051435 -0.00415866\n",
      "     0.14360099]\n",
      "   [-0.12976126 -0.1416723   0.02735071 ... -0.1041764  -0.06990647\n",
      "     0.13106053]]\n",
      "\n",
      "  [[ 0.12582286  0.02441292 -0.04855745 ... -0.1407102   0.08784954\n",
      "    -0.12565601]\n",
      "   [-0.13050358  0.12169208 -0.1548841  ... -0.06113577 -0.05473964\n",
      "    -0.13216488]\n",
      "   [-0.01086076  0.13385494  0.04279311 ... -0.14383893  0.02092473\n",
      "    -0.15837228]\n",
      "   ...\n",
      "   [-0.07197058 -0.09788089  0.14184602 ... -0.09674164 -0.06257968\n",
      "     0.15651621]\n",
      "   [ 0.05273707  0.00610638 -0.03029525 ... -0.07567036  0.08513369\n",
      "     0.05916552]\n",
      "   [ 0.1270565  -0.05982213  0.14187936 ...  0.16593008  0.06404562\n",
      "    -0.05069308]]]\n",
      "\n",
      "\n",
      " [[[-0.10436893 -0.01200958  0.00927429 ... -0.1356858   0.15679075\n",
      "    -0.10309438]\n",
      "   [-0.04330878  0.02823572 -0.09950387 ... -0.0511661   0.13774614\n",
      "    -0.04271019]\n",
      "   [-0.16550636 -0.01725364  0.05806768 ... -0.09171383  0.13388188\n",
      "     0.11229981]\n",
      "   ...\n",
      "   [-0.06227037 -0.10744576 -0.05079707 ...  0.14380689  0.06583643\n",
      "     0.11786397]\n",
      "   [ 0.00279467  0.14311962 -0.08886397 ...  0.03738828  0.15283306\n",
      "     0.06061129]\n",
      "   [ 0.12700431  0.10606746 -0.14536314 ...  0.06474161 -0.07696073\n",
      "    -0.03874879]]\n",
      "\n",
      "  [[-0.06938331  0.08854122 -0.14882326 ...  0.04520015  0.14166059\n",
      "    -0.07217288]\n",
      "   [ 0.10175116 -0.13944499  0.14752485 ...  0.01318081  0.08541454\n",
      "     0.07831152]\n",
      "   [ 0.05255187 -0.11460086 -0.04423793 ...  0.00226422 -0.12647665\n",
      "    -0.06800302]\n",
      "   ...\n",
      "   [ 0.06624222 -0.02392483  0.04499264 ... -0.16640282 -0.14473948\n",
      "     0.07331534]\n",
      "   [ 0.00491095  0.06374748  0.06393667 ...  0.08359666 -0.00167064\n",
      "    -0.08206074]\n",
      "   [-0.1263206  -0.0498101   0.01929832 ... -0.13644433  0.08239262\n",
      "     0.08185224]]\n",
      "\n",
      "  [[-0.0735037   0.10892133  0.09680165 ...  0.07669322  0.00309806\n",
      "     0.12929441]\n",
      "   [-0.03917961 -0.00835621 -0.12689611 ...  0.13431229 -0.02463067\n",
      "     0.1405875 ]\n",
      "   [ 0.0503573  -0.07953076 -0.13522427 ...  0.10173334 -0.15326738\n",
      "     0.06089596]\n",
      "   ...\n",
      "   [-0.08636765 -0.02193947 -0.07034203 ... -0.07400405 -0.0067689\n",
      "    -0.06263797]\n",
      "   [-0.02599998  0.07767732  0.05096225 ... -0.10411477  0.15205435\n",
      "    -0.1650661 ]\n",
      "   [ 0.0450948  -0.00549281 -0.04425864 ... -0.13512664  0.03585911\n",
      "    -0.06196138]]]\n",
      "\n",
      "\n",
      " [[[-0.12660956  0.12525658  0.02293503 ...  0.13625862  0.09135799\n",
      "    -0.05374782]\n",
      "   [ 0.09801222  0.16661878  0.09336717 ...  0.01332124 -0.13044044\n",
      "    -0.08501387]\n",
      "   [ 0.03994294  0.02745199 -0.07076108 ... -0.07749514  0.05341001\n",
      "     0.01932804]\n",
      "   ...\n",
      "   [-0.03261264 -0.1387026   0.16361313 ...  0.00376415  0.02601278\n",
      "    -0.10709202]\n",
      "   [-0.02233739 -0.05435427 -0.12174436 ... -0.02011049  0.08465619\n",
      "    -0.16491279]\n",
      "   [ 0.10346784 -0.01005383 -0.02015901 ... -0.0432938   0.05880535\n",
      "     0.13644831]]\n",
      "\n",
      "  [[-0.13018787  0.05497015 -0.01569574 ...  0.00029226 -0.0492508\n",
      "     0.04991972]\n",
      "   [-0.02135177  0.04722714 -0.13813853 ... -0.00984259 -0.01623528\n",
      "     0.00305736]\n",
      "   [ 0.10433765  0.04156315 -0.15267424 ... -0.03085048 -0.07144491\n",
      "     0.06117916]\n",
      "   ...\n",
      "   [ 0.058742   -0.13155863 -0.08657467 ...  0.0723749  -0.14253685\n",
      "     0.00761704]\n",
      "   [ 0.12345533  0.1355523  -0.05885359 ...  0.01358907  0.12262611\n",
      "    -0.04584523]\n",
      "   [ 0.14096148 -0.06763315  0.14289863 ... -0.04351497  0.08452256\n",
      "     0.15651037]]\n",
      "\n",
      "  [[-0.07061028  0.15252937  0.06521757 ...  0.130248   -0.05845793\n",
      "    -0.03489761]\n",
      "   [ 0.11038597 -0.03449969  0.14003734 ... -0.00601022 -0.14030878\n",
      "    -0.00041874]\n",
      "   [-0.00196166 -0.06494351 -0.14979832 ...  0.13862862  0.07843666\n",
      "    -0.14330658]\n",
      "   ...\n",
      "   [ 0.06717451 -0.07823881  0.03661723 ...  0.11769022 -0.0773588\n",
      "     0.05497067]\n",
      "   [-0.01209021 -0.03792381 -0.09090781 ...  0.04997627  0.07147796\n",
      "    -0.00790362]\n",
      "   [ 0.10289671  0.11137481 -0.15808523 ... -0.04929698 -0.05005853\n",
      "    -0.12429969]]]]\n",
      "[-0.03126008 -0.05188754 -0.08681631 -0.06363976 -0.07906317  0.10607238\n",
      " -0.11717212  0.461068   -0.22474657  0.43989366 -0.1930798  -0.22267212\n",
      "  0.01182094  0.16742626 -0.29540792 -0.14002423]\n",
      "Layer: pool3\n",
      "Layer: dense1\n",
      "[[ 1.3983371  -1.6810725   0.85803294  0.79476064 -1.183706    0.53490615\n",
      "   0.5532872  -1.2617388   0.42427707 -0.26987535]\n",
      " [-0.7704001  -1.809595    0.11771815  0.51562756 -0.31428134 -0.574213\n",
      "  -0.31721565  0.49919635  0.9375013   1.0353088 ]\n",
      " [ 1.4818628  -2.0827534   1.4642963   0.463048   -0.35812193  0.20726375\n",
      "   0.3341398  -0.4465289  -0.4623353  -1.2925293 ]\n",
      " [ 1.1518223  -1.8239592   0.23326097  1.3890829  -1.374518    0.3747423\n",
      "   0.5745137   0.34330514  0.4186258  -1.105034  ]\n",
      " [ 0.8658941  -1.8761268   0.191718    0.4986701  -1.587444    0.6729621\n",
      "  -0.8439106   1.1135765   0.20946401  0.0969484 ]\n",
      " [ 0.23726042 -0.576795   -0.2062764   0.51528424  0.31845438 -0.18082581\n",
      "  -0.17404129 -0.5815425   0.36615464  0.22499987]\n",
      " [ 0.40991777 -2.5142503   1.458699    0.83233154 -0.85153633  0.68446964\n",
      "   0.8054057  -0.860592   -0.11420973 -1.5292693 ]\n",
      " [-0.5863495   0.629958   -0.66702974 -0.24272102 -0.00574031 -0.04717582\n",
      "  -0.20521803  0.00726608 -0.30093923  0.51925933]\n",
      " [ 1.3691547  -1.6932846   1.3351952  -0.46959546 -0.5931267  -0.28147438\n",
      "   0.42680442  0.11958875 -0.48727366 -1.2005371 ]\n",
      " [-0.13570261  0.63276434  0.02514925 -0.41120383  0.45712733 -0.50535685\n",
      "  -0.24725462 -0.10606609 -0.08669039 -0.19578984]\n",
      " [ 1.5034637  -1.8824279   0.36975533 -0.3802358  -0.3026642   1.2598858\n",
      "  -0.19482562 -0.2776251  -0.22068238 -0.20084585]\n",
      " [ 1.029962   -1.9380494   1.2165853   0.618486   -0.4408712   0.29103813\n",
      "   0.10228835 -0.07482871  0.20482312 -0.7406335 ]\n",
      " [ 0.4693357  -1.7380667   1.5825257   1.1370251  -1.0517769  -0.10222831\n",
      "  -1.0177782   0.84015757 -0.1954859  -1.793763  ]\n",
      " [-0.22055963  0.20412871  0.07262845 -0.5278853  -0.09104134  0.05571676\n",
      "   0.2730834   0.06315211 -0.6070717   0.02281413]\n",
      " [-0.11256073 -1.2143472   0.03296753  0.883758   -0.5721057   0.6459599\n",
      "  -0.23803857  0.5701999   0.51024026  0.342257  ]\n",
      " [ 0.8724496  -0.6837597  -0.59910554  0.8347815  -1.2850091   0.27514803\n",
      "  -0.21944344  0.5594629   0.3770458  -0.03529979]]\n",
      "[-0.33745062  0.55698436 -0.28649804 -0.15936755  0.15731686 -0.1054851\n",
      "  0.01892249 -0.0115773   0.04407254  0.06422013]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    for weight in weights:\n",
    "        print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc5d9b-5369-42d3-807a-a310dc899876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
